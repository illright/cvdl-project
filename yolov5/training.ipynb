{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brvLsVAlo2Qu"
      },
      "source": [
        "# Draw, I'll Help\n",
        "\n",
        "This notebook contains the training code for YOLOv5 Nano for the task of shape correction in a web-based drawing app.\n",
        "\n",
        "This notebook is heavily based on the notebook from [Ultralytics's tutorial](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN5_ewYDplUr"
      },
      "source": [
        "## Step 0. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkBDW8yhqJ_j"
      },
      "source": [
        "YOLOv5 is used for training, so let's clone the source and install its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82E-tI4kqP0C"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%pip install -r yolov5/requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK01_ByOrpcy"
      },
      "source": [
        "## Step 1. Preparing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogv7GRVQ2bOw"
      },
      "source": [
        "At this step, you will need a zipped archive with the dataset in YOLOv5 format. You may either use the existing `dataset.zip` file from [Releases](https://github.com/illright/draw-ill-help/releases) or create your own dataset by uploading your annotations to Roboflow and exporting in YOLOv5 PyTorch format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBWG1EVzeGCZ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "image_size = 416  # pixels (square images assumed)\n",
        "dataset_location = Path('./dataset').resolve()\n",
        "archive_location = Path('./dataset.zip').resolve()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GqPHP1ZfNzE"
      },
      "source": [
        "If you're running this in Google Colab, run the cell below to upload the file directly. Otherwise, make sure that the dataset archive is present in the current directory under the name `dataset.zip` (unless you have changed the name in the cell above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfWAnkDGd-Th"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "archive = next(iter(files.upload().values()))\n",
        "\n",
        "with open(archive_location, 'wb') as file:\n",
        "    file.write(archive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2wGvjd4Z_92"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "os.makedirs(dataset_location)\n",
        "shutil.unpack_archive(archive_location, dataset_location)\n",
        "\n",
        "# Fix the faulty paths to the data files\n",
        "with open(dataset_location / 'data.yaml', 'w') as data:\n",
        "    print(f'train: {dataset_location / \"train\" / \"images\"}', file=data)\n",
        "    print(f'val: {dataset_location / \"valid\" / \"images\"}', file=data)\n",
        "    print('nc: 2', file=data)\n",
        "    print(\"names: ['Circle', 'Rectangle']\", file=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7yAi9hd-T4B"
      },
      "source": [
        "## Step 2. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri8BFTViG4uq"
      },
      "source": [
        "YOLOv5 Nano, pretrained on the COCO dataset, is chosen as the starting point because it yields the smallest and fastest model.\n",
        "\n",
        "The training is configured for 3000 epochs, but it is expected that the model will stop training much earlier than that due to the default patience value of early stopping being 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNYQTy7ciqUf"
      },
      "outputs": [],
      "source": [
        "%rm -rf yolov5/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaFNnxLJbq4J"
      },
      "outputs": [],
      "source": [
        "!python yolov5/train.py --img {image_size} --batch-size 256 --epochs 3000 --data {dataset_location}/data.yaml --weights yolov5n.pt --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o92QufePDnuK"
      },
      "source": [
        "## Step 3. Conversion to Tensorflow.js"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdF51PM1E139"
      },
      "source": [
        "We use the built-in converter to export the model into the format that's suitable for Tensorflow.js.\n",
        "\n",
        "The peculiar Bash snippet `$(ls ./runs/train | sort | tail -1)` simply extracts the directory of the latest train run. YOLOv5's training script produces directories `exp/`, `exp2/`, `exp3/`... in a successive fashion with every run.\n",
        "\n",
        "We specify top-K to be 1 because the web app only ever submits a single drawing to the model for prediction so there is no point in trying to find any more objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zp7MMVVD2_L"
      },
      "outputs": [],
      "source": [
        "top_k = 1\n",
        "!python yolov5/export.py --weights \"yolov5/runs/train/$(ls yolov5/runs/train | sort | tail -1)/weights/best.pt\" --img {image_size} --include tfjs  --topk-all {top_k} --topk-per-class {top_k}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fwJy32FFzvR"
      },
      "source": [
        "## Step 4. Performance evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evDueH5g3W7F"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUcr6owHF4KY"
      },
      "source": [
        "First, let's plot some charts with Tensorboard from the logfiles of YOLOv5. \n",
        "\n",
        "The logs are written to `yolov5/runs/` for each training and inference run separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLFBptEDGI18"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir yolov5/runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4qETUOf3aF-"
      },
      "source": [
        "### Testing out the model's inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XzvT46BHIAz"
      },
      "source": [
        "Now, let's run the inference on the test set of images to assess the performance of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r6PMp1oHSCS"
      },
      "outputs": [],
      "source": [
        "!python yolov5/detect.py --weights yolov5/runs/train/$(ls yolov5/runs/train | sort | tail -1)/weights/best.pt --img {image_size} --conf 0.75 --max-det 1 --source {dataset_location}/test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbUn4_b9GCKO"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "\n",
        "last_detect_run = sorted(Path('yolov5/runs/detect').glob('*'))[-1]\n",
        "\n",
        "for image_name in list(last_detect_run.glob('*.jpg')):\n",
        "    display(Image(filename=str(image_name.absolute())))\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of CVDL_Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
